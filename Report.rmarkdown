---
title: "Residency Exams"
format: pdf
fig-width: 4
fig-height: 3
geometry: top=0.7in, bottom=1in, left=0.8in, right=0.8in
header-includes:
  - \usepackage{titling}
  - \setlength{\droptitle}{-3cm}  # moves title u
---

```{r, include=FALSE}
library(lme4)
library(knitr)
library(tidyverse)
library(glmmTMB)
library(broom)
library(emmeans)
```

```{r, include=FALSE}
data <- read.table("data.txt",header = TRUE, as.is = TRUE)
```



# Background & Motivation
Prior to practicing full-time medicine, internal medicine students must complete a three year training known as a medical residency. At the end of their medical residency, they are required to pass an examination to obtain their MD. These residency programs are known for their extensive work weeks and rigorous workload. 

In 2003 and 2011, two reform policies were passed to change the structure of internal medicine residency. The 2003 reform, passed on July 1, sought to limit the shift length and number of hours worked each week by capping it at 30 hours and 80 hours, respectively. The 2011 reform, also passed on July 1, placed stricter limits on students' shift length, capping it at 16 hours for interns and 28 hours for resident students. 

These reforms were passed with the goal of improving patient care by decreasing the stress placed on internal medicine residents. In other words, with more time away from the hospital to rest and rejuvenate, students will be more successful at their jobs when they are on their shift. However, limiting the number of hours medical residents can work each week brings about several concerns regarding their performance of the examination at the end of their residency. While some believed a work time limit granted them more time to study, others thought that less hands on work would result in decreased pass rates.

These concerns bring about out motivating question: is there empirical evidence of an association between the reforms and the rate at which the medical residents passed the exam?

# Data Manipulation and Exploratory Data Analysis
The provided data set contains three columns and twenty rows, containing a column for year, number of exam takers, and pass rate as a decimal. Each rows represents a single year in which internal medicine residents completed their residency and took the examination. 



```{r}
# Data Manipulation

# Add Pass and Fail Count
data$Pass <- round(data$N * data$Pct)
data$Fail <- (data$N - data$Pass)

# Add Time Period Information
data$timeperiod <- rep(1, nrow(data))
data$timeperiod[data$Year > 2002] <- 2
data$timeperiod[data$Year > 2010] <- 3
data$timeperiod <- factor(data$timeperiod, levels = c(1, 2, 3), labels = c("tp1", "tp2", "tp3"))

kable(head(data, n = 3))
```



We manipulated the data by adding three additional columns for the number of students that passed the examination, the number of students that failed the examination, and the time period based on the year. The first time period is from 1996-2002, when there was no reform policy in place. The second time period is 2003-2010, when the first reform policy was in place. The third time period is 2011-2015, when the second reform policy was in place. 



```{r, include=FALSE}
# Relevel to Time Period Two 
yP <- data.frame(Year = rep(data$Year, data$Pass), Pass = rep(1, sum(data$Pass)))
yF <- data.frame(Year = rep(data$Year, data$Fail), Pass = rep(0, sum(data$Fail)))
y <- rbind(yP, yF); rm(yP, yF)
y$timeperiod <- rep(1, nrow(y))
y$timeperiod[y$Year > 2002] <- 2
y$timeperiod[y$Year > 2010] <- 3
y$timeperiod <- factor(y$timeperiod, levels = c(1, 2, 3), labels = c("tp1", "tp2", "tp3"))
y$timeperiod <- relevel(y$timeperiod, ref = "tp2")
data$timeperiod <- relevel(data$timeperiod, ref = "tp2")
```



We further manipulated the data by releveling to time period two. Releveling to time period two enabled us to more easily compare time period one to time period two (no reform policy to reform policy one) and time period two to time period three (reform policy one to reform policy two). 



```{r, include=FALSE}
# EDA Plot Breaking Down Subsets 

# Add Reform Phasing Information
reform_phase_data <- data |>
  mutate(
    ReformPolicy = case_when(
      Year < 2003 ~ "No Reform",
      Year < 2006 ~ "Phasing in Reform One",
      Year < 2011 ~ "Reform One",
      Year < 2014 ~ "Phasing in Reform Two",
      Year < 2016 ~ "Reform Two"
    )
  ) 
```

```{r, echo=FALSE}
# Create the Plot
reform_phase_data |>
  ggplot(aes(x = Year, y = Pct, color = ReformPolicy)) +
  geom_point(size = 2) +
    labs(
      x = "Year",
      y = "Medical Resident Exam Pass Rate",
      title = "Medical Resident Exam Pass Rate throughout Reforms"
    ) + 
  geom_vline(xintercept = c(2002.5, 2005.5, 2010.5, 2013.5)) + 
  geom_vline(xintercept = c(2002.5, 2005.5, 2010.5, 2013.5), color="red3") +
  theme_minimal()
```



The plot shown above displays the medical resident exam pass rate over the years 1996 to 2015. The plot was further split into five sections. The initial three time periods - no reform policy, reform policy one, and reform policy two - were further broken down into additional time periods. Each reform policy was split into a phasing-in time period a reform policy time period. The phasing-in time period contains the three years in which students taking the exam took some combination of the previous reform policy and the new reform policy during their three-year medical residency.

Students that fall in the section "Phasing in Reform One" (green dots on the plot), had experienced both no reform policy and reform policy one. Students that fall in the section "Phasing in Reform Two" (teal dots on the plot), had experienced both reform policy one and reform policy two during their residency. 

As can be seen from the plot, students that took the examination in years where they experienced some amount of reform policy one appeared to perform better than students that took the examination in years where they experience no reform policy or some amount of reform policy two. 

# Model Implementation Details

### Model 1 - Binomial Mixture



```{r, include=FALSE}
model <- glmer(
  Pass ~ timeperiod + (1 | Year),
  data = y,
  family = binomial(link = "logit")
)
```


We reasonably assumed that exam pass rates contain unobserved year-to-year variation, such as differences in exam difficulty or cohort quality. To capture this extra source of randomness, we fit a binomial mixture model by including a random intercept for each year. This approach allowed us to separate systematic effects of reform policies from idiosyncratic annual noise.

We fit a generalized linear mixed model (GLMM) with a logit link, specifying pass/fail outcomes as the response and reform time period as the fixed effect, with year as a random effect:

$$
\text{Pass}_{iy} \sim \text{Binomial}(n_{iy}, p_{iy}), \quad \text{logit}(p_{iy}) = \alpha + \beta \cdot \text{timeperiod}_{iy} + u_y, \quad u_y \sim N(0, \sigma^2).
$$

### Model 2 - Beta-binomial


```{r, include=FALSE}
beta_binomial_model <- glmmTMB(
  cbind(Pass, Fail) ~ timeperiod,
  data = data,
  family = betabinomial(link = "logit")
)
```



The binomial assumption may underestimate variability in exam outcomes because pass probabilities likely vary within each period. To allow for overdispersion, we modeled the yearly pass probabilities as Beta-distributed. This yields a hierarchical structure where exam outcomes are drawn from a binomial conditional on the latent Beta-distributed rate.

We fit a beta-binomial regression with time period as the predictor using the glmmTMB package with a logit link. The model structure was:
$$
\pi_y \sim \text{Beta}(\alpha, \beta), \quad \text{Pass}_y \sim \text{Binomial}(n_y, \pi_y).
$$
Here, dispersion was estimated directly from the data, capturing unmodeled heterogeneity.

### Model 3 - Beta-binomial on subset


```{r, include=FALSE}
reform_data <- data %>%
  filter(Year < 2003 | (Year >= 2006 & Year <= 2010) | (Year >= 2014 & Year <= 2015)) 
reform_data$timeperiod <- factor(reform_data$timeperiod, levels = c("tp1","tp2","tp3"))
reform_data$timeperiod <- relevel(reform_data$timeperiod, ref = "tp2")
```

```{r, include=FALSE}
beta_binomial_model_subsets <- glmmTMB(
  cbind(Pass, Fail) ~ timeperiod,
  data = reform_data,
  family = betabinomial(link = "logit")
)
```


Because policy reforms were phased in gradually, exam cohorts in transition years likely had mixed exposure. To avoid contamination, we fit the beta-binomial model on a restricted dataset excluding these phase-in years. This design isolates the effect of reforms once they were fully implemented.

We restricted the dataset to years 1996–2002, 2006–2010, and 2014–2015. The same beta-binomial specification was used, with time period as the predictor and a logit link for the mean pass probability.

# Model Evaluation
To check goodness of fit, we plotted Pearson residuals over time. We appear to minimize residuals over time in the mixture model, as seen below. Putting this together, we concluded that the full beta-binomial mixture model is the best fit.



```{r echo=FALSE}
#| out.width: "80%"
#| out.height: "auto"
knitr::include_graphics("residuals_full_vs_subset.png")

#| out.width: "80%"
#| out.height: "auto"
knitr::include_graphics("residuals_full_vs_mixture.png")


```



# Shortcomings

An issue came with finding good evaluation metrics that compare across models. We initially attempted AIC across all models, but soon learned this was not comparable for any of the models because the mixture modeling package and beta binomial packages use different formulations of AIC. In addition, AIC is dependent on the likelihood and because of this comparing AIC across a full or subset model since they utilize variable number of observations.

Looking ahead, a next step would be to use Bayesian models, which would allow us to incorporate auxiliary information into the analysis.

# Conclusion


```{r}
#| echo: false
#| tbl-cap: "GLMM (binomial mixture) fixed-effect coefficients (reference period: tp2)."
#| label: tbl:glmm-coef
tidy(model, effects = "fixed") |>
  dplyr::select(term, estimate, std.error, statistic, p.value) |>
  knitr::kable(digits = 4)
```



We concluded that the binomial mixture model is the best fit. With that model, we found that the first reform increased the odds of passing, while the second reform was associated with a decline in performance. Both of these were confirmed by significant coefficients.



```{r, include=FALSE}
emm <- emmeans(model, ~ timeperiod, type = "response", re.form = NA)
step <- as.data.frame(emm) %>%
  mutate(period = c("tp2","tp1","tp3")) %>%
  arrange(period)

nm_mean  <- intersect(names(step), c("response","prob","emmean"))[1]
nm_lower <- intersect(names(step), c("lower.CL","asymp.LCL"))[1]
nm_upper <- intersect(names(step), c("upper.CL","asymp.UCL"))[1]

step$response <- step[[nm_mean]]
step$lower.CL <- step[[nm_lower]]
step$upper.CL <- step[[nm_upper]]

step$xmin <- c(1996, 2003, 2011)
step$xmax <- c(2002, 2010, 2015)
```

```{r}
#| label: fig:glmm-final
#| echo: false
#| fig-cap: "Final GLMM (binomial mixture) step fit summarizing period-level pass probabilities with 95% CIs."
#| fig-alt: "Yearly pass rates with horizontal fitted levels and dotted confidence bands from the GLMM."
ggplot(data, aes(x = Year, y = Pass/N)) +
  geom_point(color = "forestgreen") +
  geom_vline(xintercept = c(2003, 2011), color = "red3") +
  geom_segment(data = step,
               aes(x = xmin, xend = xmax, y = response, yend = response),
               inherit.aes = FALSE, linewidth = 1) +
  geom_segment(data = step,
               aes(x = xmin, xend = xmax, y = lower.CL, yend = lower.CL),
               inherit.aes = FALSE, linetype = "dotted") +
  geom_segment(data = step,
               aes(x = xmin, xend = xmax, y = upper.CL, yend = upper.CL),
               inherit.aes = FALSE, linetype = "dotted") +
  labs(y = "Pass Rate") +
  coord_cartesian(ylim = c(0.80, 0.96)) +
  theme_minimal()
```



# Citations
https://www.bmj.com/content/366/bmj.l4134#:~:text=The%20first%20reform%2C%20in%202003,the%20period%20of%20these%20reforms. 
https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/1672284

